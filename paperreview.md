---
title: "Paper Review Project"
layout: default
permalink: /paper-review/
---

# Paper Review 

The 2025 edition of the course CS-E4740 includes the option to complete a paper review instead (or on top) of the regular 
assignments. Completing a review will deepen your understanding of federated learning and improve your critical analysis 
skills. Below is a curated list of research papers for students to choose from. These papers focus on federated learning, 
covering foundational concepts, advanced techniques, and real-world applications. The main focus of your review should 
be how the methods presented in the paper relate to the theoretical concepts and algorithms covered in our course. 

## Instructions
1. **Choose a Paper:** Select a paper from the list below or propose one (with instructor approval).
2. **Review Structure:** Your review should include the following sections:
   - **Summary:** Summarize the main contributions and methodology.
   - **Comparison to Generalized Total Variation Framework:** Compare the proposed methods with the GTV minimization 
   framework discussed in the lectures and the [Federated Learning Book](https://github.com/alexjungaalto/FederatedLearning/blob/main/material/FLBook.pdf). Highlight similarities, differences, and how the methods build upon or diverge from the framework.
   - **Strengths:** Discuss what the paper does well.
   - **Weaknesses:** Point out limitations or areas for improvement.
3. **Deliverables:** 
   - A **slide deck** summarizing your review.
   - A **recorded slide talk** (maximum 10 minutes) explaining your findings.
4. **Submission Deadline:** [TBD]

## Paper List

### Foundational Papers

- McMahan, H. B., et al. (2017). "Communication-Efficient Learning of Deep Networks from Decentralized Data."
  - [DOI:10.48550/arXiv.1602.05629](https://arxiv.org/abs/1602.05629)
  - A pioneering work that introduces the concept of federated learning.

- Kairouz, P., et al. (2019). "Advances and Open Problems in Federated Learning."
  - [DOI:10.48550/arXiv.1912.04977](https://arxiv.org/abs/1912.04977)
  - A comprehensive survey of the state-of-the-art in federated learning and its challenges.

### Privacy and Security in Federated Learning
- Geyer, R. C., Klein, T., & Nabi, M. (2017). "Differentially Private Federated Learning: A Client Level Perspective."
  - [DOI:10.1109/GLOCOM.2017.8253396](https://doi.org/10.1109/GLOCOM.2017.8253396)
  - Explores privacy preservation in federated learning through differential privacy.

- Bonawitz, K., et al. (2017). "Practical Secure Aggregation for Privacy-Preserving Machine Learning."
  - [DOI:10.1145/3133956.3133982](https://doi.org/10.1145/3133956.3133982)
  - Proposes a secure aggregation protocol to protect data during training.
  
 - J. Geiping, et al. (2017). "Inverting Gradients - How easy is it to break privacy in federated learning?"
  - [abstract](https://papers.nips.cc/paper/2020/hash/c4ede56bbd98819ae6112b20ac6bf145-Abstract.html)
 
  

### Optimization and Communication Efficiency
- Smith, V., et al. (2017). "Federated Multi-Task Learning."
  - [DOI:10.48550/arXiv.1705.10467](https://arxiv.org/abs/1705.10467)
  - Extends federated learning to handle multiple related tasks across clients.

- Sattler, F., et al. (2019). "Clustered Federated Learning: Model-Agnostic Distributed Multi-Task Optimization under Privacy Constraints."
  - [DOI:10.48550/arXiv.1910.01991](https://arxiv.org/abs/1910.01991)
  - Introduces a clustered approach to federated learning for heterogeneous data.

### Federated Learning Applications

- Yang, Q., et al. (2019). "Federated Machine Learning: Concept and Applications."
  - [DOI:10.1145/3298981](https://doi.org/10.1145/3298981)
  - Provides practical insights and applications of federated learning in real-world scenarios.

- Li, T., et al. (2020). "Federated Optimization in Heterogeneous Networks."
  - [DOI:10.48550/arXiv.1812.06127](https://arxiv.org/abs/1812.06127)
  - Discusses optimization techniques for federated learning in settings with non-IID data.
  
- Douillard, A., et.al. (2023). "DiLoCo: Distributed Low-Communication Training of Language Models."
  - [DOI:10.48550/arXiv.2311.08105](https://arxiv.org/abs/2311.08105)
  - Proposes methods for distributed training of language models with reduced communication overhead.
  
- N. Mendes, et.al. (2024) "Federated learning framework for prediction of net energy demand in transactive energy communities." 

 - Q Arooj (2024), "FedWindT: Federated learning assisted transformer architecture for collaborative and secure wind power forecasting in diverse conditions."
 
- R. Doriguzzi-Corin, D. Siracusa (2024), "FLAD: Adaptive Federated Learning for DDoS attack detection."
Computers & Security,
Volume 137,
  

## Propose a Paper
If you wish to review a paper not listed here, please email [your email address] with the title, authors, and a brief justification for your choice.

---

Feel free to reach out with any questions or for further guidance!
